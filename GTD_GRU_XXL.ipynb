{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "1a8XjhsuFNjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d557d87-25c8-4a94-8e06-7f3270968073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as n\n",
        "import os\n",
        "import json\n",
        "import re"
      ],
      "metadata": {
        "id": "BfnW2zrHFIoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3PzeMo121l-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "mXNaNZJNFFbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/Data/gtdnorm.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "9aSDXk3WFTDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "OxODAnxjFZWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in df.iloc[0]:\n",
        "  if not (i >= 0 and i <= 1):\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "W9kDvh14HW8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a90e343-f54b-48e5-b0c3-2bdec44f46da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "lB_3YwT9GqLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[0:93500]"
      ],
      "metadata": {
        "id": "oWrLTz6mIQwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GTD(Dataset):\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.x = torch.tensor(df[[i for i in df.columns if i != 'target']].values, dtype=torch.float32)\n",
        "        self.y = torch.tensor(df.target.values, dtype=torch.long)\n",
        "        self.n_samples = len(df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.x[index]\n",
        "        y = self.y[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "OE9E0d9dGel8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gtd_ds = GTD(df)"
      ],
      "metadata": {
        "id": "0O0B-FDKJfEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(gtd_ds)"
      ],
      "metadata": {
        "id": "fwJSZTl0IWkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317baafa-f1ab-479b-e953-8cd8f8fe6186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93500"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "train_size = int(0.8 * len(df))\n",
        "test_size = len(df) - train_size\n",
        "train_dataset, test_dataset = random_split(gtd_ds, [train_size, test_size])"
      ],
      "metadata": {
        "id": "wjAkdRHHISOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "num_iters = 3000\n",
        "input_dim = df.shape[1]-1 # num_features = 43\n",
        "num_hidden = 100 # num of hidden nodes\n",
        "output_dim = len(df.target.unique()) #11\n",
        "\n",
        "learning_rate = 0.001  # More power so we can learn faster! previously it was 0.001"
      ],
      "metadata": {
        "id": "8gzaFxgVPdbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25 #num_iters / (len(train_dataset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "5vlTFJctH3e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_loader:\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "id": "UBWJ3YcKP3sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9996275c-3837-4431-c53f-8ce07f9209d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[0.5197, 0.5361, 0.8195,  ..., 1.0000, 0.0000, 1.0000],\n",
            "        [0.3525, 0.5571, 0.4635,  ..., 0.9000, 0.0000, 0.9000],\n",
            "        [0.5521, 0.5140, 0.5372,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        ...,\n",
            "        [0.5038, 0.5683, 0.6424,  ..., 1.0000, 0.0000, 1.0000],\n",
            "        [0.4118, 0.4863, 0.5988,  ..., 0.0000, 0.0000, 0.0000],\n",
            "        [0.5774, 0.4703, 0.4973,  ..., 0.0000, 0.0000, 0.0000]]), tensor([ 4,  9, 10,  4,  0, 10, 10,  0,  0, 10,  0,  6, 10,  3,  5, 10,  0,  0,\n",
            "         0,  0,  6,  0,  0,  0,  0,  0,  0,  0,  3,  6,  0,  0,  0,  0, 10,  4,\n",
            "         0, 10,  0, 10,  0, 10,  0, 10,  0,  0,  0, 10, 10,  0,  1, 10,  0, 10,\n",
            "         0,  0, 10,  0, 10,  0,  0, 10,  2,  0,  0,  0,  1,  0,  0,  1,  0,  0,\n",
            "        10,  1,  1,  2,  0, 10,  1,  0, 10,  0, 10,  5,  0,  0, 10,  0,  0,  0,\n",
            "         0,  5, 10,  6,  0,  0,  0,  2, 10,  0])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        out, _ = self.gru(x, (h0.detach()))\n",
        "\n",
        "        # Index hidden state of last time step\n",
        "        out = self.fc(self.relu(out[:, -1, :]))\n",
        "\n",
        "        return out\n",
        "\n",
        "# Define hyperparameters\n",
        "input_size = input_dim  # Number of input features\n",
        "hidden_size = 64  # Number of LSTM units\n",
        "num_layers = 2  # Number of LSTM layers\n",
        "output_size = 11  # Number of output classes\n",
        "\n",
        "# Instantiate the model\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "mLtoQOwC4v-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a8195a-f7ef-4bba-983f-276e75862141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (gru): GRU(1579, 64, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=64, out_features=11, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "x_DzSa3SOYdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000"
      ],
      "metadata": {
        "id": "g6YssAGNRXA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = inputs.reshape(100, 1, input_dim)"
      ],
      "metadata": {
        "id": "3STuMiq4LFGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "bcb2e50f-c42b-41b7-8fee-bc51bccdb9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-9de1bd55b48e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "BIjQeMpSL760"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for i, (inputs, labels) in enumerate(train_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(inputs.reshape(100, 1, input_dim))\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      iter += 1\n",
        "\n",
        "  print('Epoch [{}/{}] Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "id": "8xbmmsnHN2hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "399LqT5TbM4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yp = np.array([])\n",
        "yt = np.array([])\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "for input, labels in test_loader:\n",
        "\n",
        "                input = input.to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(input.reshape(100, 1, input_dim))\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "\n",
        "                yp = np.concatenate((yp, predicted.numpy()))\n",
        "                yt = np.concatenate((yt, labels.numpy()))\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "print(yt.shape, yp.shape)\n",
        "print(yt[:10])\n",
        "print(yp[:10])\n"
      ],
      "metadata": {
        "id": "C-o_KW7saiLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = correct / total * 100\n",
        "accuracy"
      ],
      "metadata": {
        "id": "IgS9UnKPWrs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = yt==yp\n",
        "print(res.sum())"
      ],
      "metadata": {
        "id": "3QKroT1ycYwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "cm = metrics.confusion_matrix(yt, yp)"
      ],
      "metadata": {
        "id": "TSdu5Kj0chvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "id": "TBMybmOKjx_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "FOza3xkNj2U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9, 9))\n",
        "sns.heatmap(cm, annot = True, fmt = '0.3f', linewidth = 0.5, square = True, cbar = False)\n",
        "plt.ylabel('Actual Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show"
      ],
      "metadata": {
        "id": "Ov11LQzSj9p3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(yt, yp))"
      ],
      "metadata": {
        "id": "D3gWd6gpkv77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}